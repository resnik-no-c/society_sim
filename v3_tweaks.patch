--- constraint_simulation_v3.py.orig	2025-01-21 10:00:00.000000000 +0000
+++ constraint_simulation_v3.py	2025-01-21 10:30:00.000000000 +0000
@@ -1,4 +1,5 @@
 #!/usr/bin/env python3
+import math
 """
 Enhanced Constraint Cascade Simulation v3 - Streamlined 13-Parameter Implementation
 Implements the v3 simulation design with focused 13-parameter API while preserving all functionality.
@@ -158,7 +159,7 @@
 @dataclass
 class FastRelationship:
     """Enhanced relationship tracking"""
-    trust: float = 0.5
+    trust: float = None  # Will be initialized with beta distribution
     interaction_count: int = 0
     cooperation_history: deque = field(default_factory=lambda: deque(maxlen=40))
     last_interaction_round: int = 0
@@ -166,6 +167,11 @@
     betrayal_count: int = 0
     cooperation_count: int = 0
     
+    def __post_init__(self):
+        """Initialize trust with diversity if not set"""
+        if self.trust is None:
+            self.trust = random.betavariate(2, 2)  # Trust diversity initialization
+    
     def update_trust(self, cooperated: bool, round_num: int, base_delta: float,
                     group_bias: float = 1.0, out_group_bias: float = 1.0):
         """Update trust based on v3 parameter system"""
@@ -178,7 +184,8 @@
             self.trust = min(1.0, self.trust + delta)
         else:
             self.betrayal_count += 1
-            delta = -base_delta * (group_bias if self.is_same_group else out_group_bias)
+            # Asymmetric trust updates - betrayal hurts 2.5x more than cooperation helps
+            delta = -2.5 * base_delta * (group_bias if self.is_same_group else out_group_bias)
             self.trust = max(0.0, self.trust + delta)
 
 @dataclass
@@ -194,8 +201,12 @@
     base_trust_delta: float  # uniform(0.05, 0.20)
     group_trust_bias: float  # uniform(1.2, 2.0)
     resilience_profile: Dict[str, float]  # threshold ∈ [0.1,0.4], noise ∈ [0.0,0.15]
     turnover_rate: float  # uniform(0.02, 0.05)
     social_diffusion: float  # uniform(0.0, 0.10)
+    
+    # Enhanced v3 parameters with proper defaults
+    severity_pareto_alpha: float = 1.5  # Heavier-tailed shock severity
+    collapse_speed: float = 0.2  # Separate collapse vs recovery speeds
+    recovery_speed: float = 0.05
+    coalition_threshold: int = 5  # Minimum intergroup interactions for coalition bonus
     max_rounds: int = DEFAULT_MAX_ROUNDS
     
     # Legacy parameters preserved for compatibility
@@ -212,6 +223,10 @@
     def __post_init__(self):
         """Validate parameters after initialization"""
+        # Update resilience profile defaults if using legacy values
+        if isinstance(self.resilience_profile, dict):
+            if self.resilience_profile.get('noise', 0) > 0.05:
+                self.resilience_profile['noise'] = 0.05  # Enforce reduced noise
+        
         # Validate v3 parameters
         assert self.shock_interval_years in [10, 15, 20, 25], f"Invalid shock_interval_years: {self.shock_interval_years}"
         assert 0.0 <= self.homophily_bias <= 0.8, f"Invalid homophily_bias: {self.homophily_bias}"
@@ -236,7 +251,7 @@
         assert 'threshold' in self.resilience_profile, "Missing threshold in resilience_profile"
         assert 'noise' in self.resilience_profile, "Missing noise in resilience_profile"
         assert 0.1 <= self.resilience_profile['threshold'] <= 0.4, f"Invalid resilience threshold: {self.resilience_profile['threshold']}"
-        assert 0.0 <= self.resilience_profile['noise'] <= 0.15, f"Invalid resilience noise: {self.resilience_profile['noise']}"
+        assert 0.0 <= self.resilience_profile['noise'] <= 0.05, f"Invalid resilience noise: {self.resilience_profile['noise']}"
 
 @dataclass
 class EnhancedSimulationResults:
@@ -288,6 +303,12 @@
     group_extinction_events: int = 0
     trust_asymmetry: float = 0.0
     
+    # Enhanced tracking metrics
+    group_cooperation_benefits: Dict[str, float] = field(default_factory=dict)
+    group_constraint_penalties: Dict[str, float] = field(default_factory=dict)
+    institutional_memory: float = 0.0
+    lineage_depth_avg: float = 0.0
+    
     # Interaction metrics
     total_interactions: int = 0
     total_mutual_coop: int = 0
@@ -331,7 +352,8 @@
                  'rounds_as_cooperative', 'maslow_needs', 'maslow_pressure', 'is_born',
                  'group_id', 'in_group_interactions', 'out_group_interactions', 
                  'mixing_event_participations', 'acute_stress', 'chronic_queue', 
-                 'base_coop', 'society_trust', 'resilience_threshold', 'resilience_noise']
+                 'base_coop', 'society_trust', 'resilience_threshold', 'resilience_noise',
+                 'parent_id', 'lineage_depth', 'network_neighbors']  # Enhanced tracking
     
     def __init__(self, person_id: int, params: SimulationConfig, 
                  parent_a: Optional['OptimizedPerson'] = None, 
@@ -345,6 +367,16 @@
         self.is_dead = False
         self.is_born = (parent_a is not None and parent_b is not None)
         
+        # Lineage tracking for intergenerational transmission
+        if parent_a is not None:
+            self.parent_id = parent_a.id
+            self.lineage_depth = max(getattr(parent_a, 'lineage_depth', 0), 
+                                   getattr(parent_b, 'lineage_depth', 0)) + 1
+        else:
+            self.parent_id = None
+            self.lineage_depth = 0
+        
+        self.network_neighbors = set()  # For social diffusion
         # v3 resilience profile with per-agent variation (FIXED: proper bounds checking)
         base_threshold = params.resilience_profile['threshold']
         noise_range = params.resilience_profile['noise']
@@ -428,36 +460,55 @@
         self.maslow_pressure = max(0, total_pressure - total_relief)
     
     def calculate_cooperation_decision(self, other: 'OptimizedPerson', round_num: int, params: SimulationConfig) -> bool:
-        """v3 cooperation decision using resilience profile (FIXED: more robust logic)"""
+        """UNIFIED v3 cooperation decision with ALL enhancements"""
         if self.strategy == 'selfish':
             return False
         
-        # Small chance of random defection
-        if random.random() < 0.02:
+        # 1. MASLOW HIERARCHY OVERRIDE - Force defection under severe need deprivation
+        if (self.maslow_needs.physiological < 2.0 or self.maslow_needs.safety < 2.0):
+            if random.random() < 0.8:  # 80% chance of forced defection
+                return False
+        
+        # 2. ACUTE STRESS BOOST - Get from simulation context
+        acute_boost = getattr(params, '_acute_boost', 1.0)
+        
+        # 3. RESILIENCE THRESHOLD with reduced noise
+        noise_adjustment = random.uniform(-self.resilience_noise, self.resilience_noise)
+        effective_threshold = self.resilience_threshold + noise_adjustment
+        effective_threshold = max(0.01, min(0.99, effective_threshold))
+        
+        # 4. BASE COOPERATION PROBABILITY calculation
+        relationship = self.get_relationship(other.id, round_num, getattr(other, 'group_id', None))
+        
+        if relationship.interaction_count == 0:
+            # First interaction - use resilience-based probability
+            base_prob = 1 - effective_threshold
+        else:
+            # Trust-based decision
+            base_prob = relationship.trust
+            
+        # 5. APPLY ACUTE BOOST
+        base_prob *= acute_boost
+        
+        # 6. COALITION BONUS for 3+ groups (REPLACES old group bias)
+        if (params.num_groups >= 3 and 
+            hasattr(self, 'group_id') and hasattr(other, 'group_id') and 
+            self.group_id != other.group_id and 
+            self.out_group_interactions >= params.coalition_threshold):
+            base_prob += 0.05
+            
+        # 7. FRACTURE PENALTY for single-group societies
+        if params.num_groups == 1:
+            time_factor = round_num / params.max_rounds
+            base_prob -= 0.02 * time_factor
+            
+        # 8. POSITIVE MASLOW OVERRIDES
+        maslow_priority = self._get_maslow_priority_override()
+        if maslow_priority == 'self_actualization_boost':
+            base_prob *= 1.2   # Self-actualization lift
+        elif maslow_priority == 'group_seeking':
+            base_prob += 0.05  # Belonging boost
+        
+        # 9. RANDOM DEFECTION chance
+        if random.random() < 0.02:
             return False
-        
-        # Use resilience threshold with noise (FIXED: safer bounds)
-        noise_adjustment = random.uniform(-self.resilience_noise, self.resilience_noise)
-        effective_threshold = self.resilience_threshold + noise_adjustment
-        effective_threshold = max(0.01, min(0.99, effective_threshold))
-        
-        relationship = self.get_relationship(other.id, round_num, getattr(other, 'group_id', None))
-        
-        if relationship.interaction_count == 0:
-            # First interaction - use base probability
-            base_prob = 1 - effective_threshold  # Higher threshold = lower cooperation
-            
-            # Group-based modification
-            if hasattr(self, 'group_id') and hasattr(other, 'group_id'):
-                if self.group_id == other.group_id:
-                    base_prob *= 1.2  # More likely to cooperate with in-group
-                else:
-                    base_prob *= 0.8  # Less likely with out-group
-            
-            return random.random() < max(0.05, min(0.95, base_prob))
-        else:
-            # Trust-based decision - cooperate if trust exceeds threshold
-            return relationship.trust >= effective_threshold
+            
+        # 10. FINAL DECISION with bounds
+        final_prob = max(0.05, min(0.95, base_prob))
+        return random.random() < final_prob
     
     def get_relationship(self, other_id: int, round_num: int, 
                         other_group_id: Optional[str] = None) -> FastRelationship:
@@ -471,6 +522,22 @@
             relationship = FastRelationship(is_same_group=is_same_group)
             self.relationships[other_id] = relationship
         return self.relationships[other_id]
+    
+    def _get_maslow_priority_override(self) -> str:
+        """Determine if Maslow needs create cooperation override"""
+        if self.maslow_needs.self_actualization > 8.0:
+            return 'self_actualization_boost'
+        elif self.maslow_needs.love < 4.0:
+            return 'group_seeking'
+        return 'none'
+    
+    def check_for_collapse(self, params: SimulationConfig) -> bool:
+        """Check if person should collapse to selfish strategy"""
+        if (self.strategy == 'cooperative' and 
+            self.constraint_level > self.constraint_threshold):
+            if random.random() < params.collapse_speed:
+                self.force_switch()
+                return True
+        return False
     
     def update(self, system_stress: float, params: SimulationConfig, cooperation_bonus: float = 0):
         """Update person state"""
@@ -540,8 +607,8 @@
         
         if random.random() < recovery_chance:
-            self.switch_to_cooperative()
-            return True
+            if random.random() < params.recovery_speed:
+                self.switch_to_cooperative()
+                return True
         return False
     
     def force_switch(self):
@@ -621,13 +688,15 @@
             resilience_profile={
                 'threshold': random.uniform(0.1, 0.4),
-                'noise': random.uniform(0.0, 0.15)
+                'noise': random.uniform(0.0, 0.05)  # Reduced recovery noise
             },
             turnover_rate=random.uniform(0.08, 0.05),
             social_diffusion=random.uniform(0.0, 0.10),
+            severity_pareto_alpha=random.uniform(1.2, 1.8),
+            collapse_speed=random.uniform(0.15, 0.25),
+            recovery_speed=random.uniform(0.03, 0.07),
             max_rounds=DEFAULT_MAX_ROUNDS
         )
         
         return config
@@ -642,7 +711,10 @@
             group_trust_bias=1.6,
-            resilience_profile={'threshold': 0.25, 'noise': 0.075},
+            resilience_profile={'threshold': 0.25, 'noise': 0.05},
+            severity_pareto_alpha=1.5,
+            collapse_speed=0.2,
+            recovery_speed=0.05,
             turnover_rate=0.035,
             social_diffusion=0.05,
             max_rounds=DEFAULT_MAX_ROUNDS
@@ -783,6 +855,7 @@
         self.params = params
         self.run_id = run_id
         self.people: List[OptimizedPerson] = []
         self.round = 0
+        self.acute_boost = 1.0  # Acute vs. chronic stress boost
         self.system_stress = 0.0
         self.next_person_id = params.initial_population + 1
         
@@ -811,11 +884,21 @@
         self.social_diffusion_log_counter = 0
         self.network_topology_log_counter = 0
         
+        # Enhanced tracking
+        self.group_cooperation_benefits = defaultdict(float)
+        self.group_constraint_penalties = defaultdict(float)
+        self.institutional_memory = 0.0
+        
         self._initialize_population()
     
     def _initialize_population(self):
         """Initialize population with group distribution (FIXED: proper group assignment)"""
         for i in range(1, self.params.initial_population + 1):
             person = OptimizedPerson(i, self.params)
             self.people.append(person)
+        
+        # Initialize network neighbors for social diffusion
+        for person in self.people:
+            potential_neighbors = [p.id for p in self.people if p.id != person.id]
+            num_neighbors = min(5, len(potential_neighbors))
+            if potential_neighbors:
+                person.network_neighbors = set(random.sample(potential_neighbors, num_neighbors))
     
     def _sample_next_shock(self) -> int:
@@ -840,13 +923,20 @@
         self.system_stress += shock_severity
         self.shock_events += 1
         
+        # Acute vs. chronic stress boost
+        if self.shock_events <= 2:
+            self.acute_boost = 1.0 + math.exp(-self.shock_events)
+        else:
+            self.acute_boost = 1.0
+        
+        # Store acute boost in params for access by agents
+        self.params._acute_boost = self.acute_boost
+        
         # Apply shock to all people
         alive_people = [p for p in self.people if not p.is_dead]
         for person in alive_people:
             try:
                 person.acute_stress += shock_severity * 0.5  # Scale down shock impact
                 person.chronic_queue.append(person.acute_stress)
             except Exception as e:
                 timestamp_print(f"⚠️ Error applying shock to person {person.id}: {e}")
                 continue
@@ -856,7 +946,7 @@
     
     def _draw_shock_magnitude(self) -> float:
         """Draw shock magnitude from Pareto distribution (FIXED: bounded output)"""
-        alpha = 2.0  # Fixed for now, could be parameterized
+        alpha = self.params.severity_pareto_alpha
         xm = 0.3
         try:
             u = random.uniform(0.001, 0.999)  # Avoid extreme values
@@ -877,6 +967,11 @@
         if len(alive_people) < 2 or self.params.num_groups <= 1:
             return
             
+        # Stress-conditioned intervention efficacy
+        max_stress = max(self.system_stress_history) if self.system_stress_history else 1.0
+        stress_factor = max(0.0, 1.0 - self.system_stress / max_stress)
+        effect = self.params.intervention_scale * stress_factor
+        
         self.total_mixing_events += 1
         
         # Select agents for intervention
         try:
-            num_selected = max(1, int(len(alive_people) * self.params.intervention_scale))
+            num_selected = max(1, int(len(alive_people) * effect))
             num_selected = min(num_selected, len(alive_people))
             selected_agents = random.sample(alive_people, num_selected)
             
+            stress_conditioned_bonus = self.params.event_bonus * stress_factor
             # Apply event bonus to their interactions
             for agent in selected_agents:
                 agent.mixing_event_participations += 1
-                # Boost trust temporarily (but safely)
+                # Boost trust temporarily (scaled by stress-conditioned effect)
                 for rel in agent.relationships.values():
-                    boost_factor = min(1.5, self.params.event_bonus)  # Cap boost
+                    boost_factor = min(1.5, stress_conditioned_bonus)
                     rel.trust = min(1.0, rel.trust * boost_factor)
+                
+                # constraint relief scales with stress_factor
+                agent.constraint_level = max(0.0,
+                    agent.constraint_level - 0.05 * stress_factor)
             
             if len(selected_agents) > 1:
                 self.successful_mixing_events += 1
@@ -901,27 +996,35 @@
     def _apply_social_diffusion(self, alive_people: List[OptimizedPerson]):
-        """Apply social diffusion of trust values (FIXED: handle edge cases)"""
-        if self.params.social_diffusion <= 0:
+        """Apply network-neighbor diffusion of trust and update institutional memory."""
+        sd = self.params.social_diffusion
+        if sd <= 0:
             return
-        
-        try:
-            # Calculate average neighbor trust for each person
-            for person in alive_people:
-                if not person.relationships:
-                    continue  # Skip people with no relationships
-                    
-                trust_values = [rel.trust for rel in person.relationships.values()]
-                if not trust_values:
-                    continue
-                    
-                avg_neighbor_trust = np.mean(trust_values)
-                
-                # Smooth trust values toward network average
-                for rel in person.relationships.values():
-                    old_trust = rel.trust
-                    new_trust = ((1 - self.params.social_diffusion) * old_trust + 
-                                self.params.social_diffusion * avg_neighbor_trust)
-                    rel.trust = max(0.0, min(1.0, new_trust))  # Ensure bounds
-                    
-        except Exception as e:
-            timestamp_print(f"⚠️ Error in social diffusion: {e}")
+        total = 0.0
+        count = 0
+        for person in alive_people:
+            neighbors = getattr(person, 'network_neighbors', set())
+            if not neighbors:
+                continue
+            vals = [person.relationships[n].trust
+                    for n in neighbors if n in person.relationships]
+            if not vals:
+                continue
+            local = sum(vals) / len(vals)
+            total += local
+            count += 1
+            for n in neighbors:
+                if n in person.relationships:
+                    r = person.relationships[n]
+                    r.trust = max(0.0, min(1.0,
+                        (1-sd)*r.trust + sd*local
+                    ))
+        # institutional memory: decay or reinforce
+        if count:
+            net_avg = total / count
+            self.institutional_memory = (1-sd)*self.institutional_memory + sd*net_avg
+        else:
+            self.institutional_memory *= (1 - sd*0.1)
+    
+    def _apply_group_penalties(self, alive_people: List[OptimizedPerson]):
+        """Apply group-specific penalties including homogeneity fracture"""
+        if not alive_people:
+            return
+            
+        # Fracture penalty for fully homogeneous societies
+        if self.params.num_groups == 1:
+            time_factor = self.round / self.params.max_rounds
+            penalty = 0.02 * time_factor
+            
+            for person in alive_people:
+                person.add_constraint_pressure(penalty, False, 1.0)
+                self.group_constraint_penalties['homogeneity'] += penalty
     
     def _create_birth(self, parent_a: OptimizedPerson, parent_b: OptimizedPerson):
         """Create new person with group inheritance"""
@@ -932,8 +1035,19 @@
     def _check_recoveries(self):
-        """Check for strategy recoveries"""
+        """Check for strategy changes with separate collapse/recovery logic"""
         alive_people = [p for p in self.people if not p.is_dead]
+        
+        # Determine if we're in collapse or recovery phase
+        current_coop_rate = len([p for p in alive_people if p.strategy == 'cooperative']) / max(1, len(alive_people))
+        in_collapse_phase = current_coop_rate < 0.3
+        
         for person in alive_people:
-            if person.check_for_recovery(self.params):
+            if in_collapse_phase:
+                # Use collapse dynamics
+                if person.check_for_collapse(self.params):
+                    self.total_defections += 1
+            else:
+                # Use recovery dynamics
+                if person.check_for_recovery(self.params):
                 self.total_redemptions += 1
     
     def _update_population(self):
@@ -944,22 +1058,36 @@
         
         for person in self.people:
             person.update(self.system_stress, self.params)
+            
+        # Update acute boost decay
+        if self.acute_boost > 1.0:
+            self.acute_boost = max(1.0, self.acute_boost - 0.02)
+            self.params._acute_boost = self.acute_boost
     
     def _collect_round_data(self):
-        """v3 logging with variable frequencies"""
+        """v3 logging with variable frequencies and enhanced metrics"""
         alive_people = [p for p in self.people if not p.is_dead]
         
         # Per-round metrics (always collected)
         self.system_stress_history.append(self.system_stress)
         self.population_history.append(len(alive_people))
         
+        # ENHANCED METRICS:
+        if alive_people:
+            # lineage depth
+            self._current_lineage_depth = (
+                sum(p.lineage_depth for p in alive_people) / len(alive_people)
+            )
+            # group benefits/penalties accumulate
+            for p in alive_people:
+                gid = getattr(p, 'group_id', 'default')
+                if p.strategy == 'cooperative':
+                    self.group_cooperation_benefits[gid] += 0.01
+                else:
+                    self.group_constraint_penalties[gid] += 0.01
+        
         # Maslow needs logging (every 4 rounds)
         if self.round % 4 == 0:
             self.maslow_log_counter += 1
-            # Placeholder for Maslow logging - could expand if needed
         
         # Social diffusion logging (every 8 rounds)
         if self.round % 8 == 0:
@@ -1021,6 +1149,9 @@
                     # Apply social diffusion (FIXED: safer application)
                     try:
                         self._apply_social_diffusion(alive_people)
+                        
+                        # Apply group penalties
+                        self._apply_group_penalties(alive_people)
                     except Exception as e:
                         timestamp_print(f"⚠️ Error in social diffusion round {self.round}: {e}")
                     
@@ -1177,6 +1308,12 @@
             out_group_constraint_amplifications=self.out_group_constraint_amplifications,
             group_extinction_events=group_extinctions,
             trust_asymmetry=trust_asymmetry,
+            
+            # Enhanced tracking metrics
+            group_cooperation_benefits=dict(self.group_cooperation_benefits),
+            group_constraint_penalties=dict(self.group_constraint_penalties),
+            institutional_memory=self.institutional_memory,
+            lineage_depth_avg=getattr(self, '_current_lineage_depth', 0.0),
             
             # Interaction metrics
             total_interactions=total_interactions,